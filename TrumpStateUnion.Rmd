---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(twitteR)
library(httr)
library(tm)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(wordcloud2)
library(tidytext)
library(scales)
library(stringr)


tweet.df<-read.csv("TrumpStateUnion.csv")


tot.tweet <-paste(tweet.df$text, collapse = " ")#make into a string

tweet.df$text <- sapply(tweet.df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))#removes emojis/problem Characters


corp.tweet<-Corpus(VectorSource(tweet.df$text))#to Corpus

clean.corp<-tm_map(corp.tweet, content_transformer(tolower))
removeURL<- function(x) gsub("http[^[ : space: ]]*", " ", x)
clean.corp<-tm_map(clean.corp, content_transformer(removeURL))
clean.corp<-tm_map(clean.corp, removeNumbers)
clean.corp<-tm_map(clean.corp, removePunctuation)
clean.corp<-tm_map(clean.corp, removeWords, stopwords('english'))
clean.corp<-tm_map(clean.corp, removeWords, c("realdonaldtrump","realdonaldtrumps"))#had to remove, dominated the word frequency charts
clean.corp<-tm_map(clean.corp, stripWhitespace)

#cleaning process



trump.dtm<-DocumentTermMatrix(clean.corp)#corp to documenttermmatrix

tidy.trump<-tidy(trump.dtm)#coercing into a tiddle


tidy.trump%>%
  count(term, sort = TRUE)%>%
  filter(n > 75) %>%
  mutate(term = reorder(term, n)) %>%
  ggplot(aes(term, n, fill = n)) + 
  geom_col()+
  coord_flip()#freq count and visulization

cloud.tweet<-tidy.trump%>%
  count(term, sort = TRUE)#word clouds are fun

wordcloud2(cloud.tweet, backgroundColor = "black")# the Donald is too big for this. 


tidy.trump1<-tweet.df%>%
  unnest_tokens(word, text)%>%
  count(word, sort = TRUE) %>%
  ungroup()

total.count<-tidy.trump1 %>%
  mutate(total = sum(n))#adding a total column

Trump_tf<-total.count %>%
  mutate(rank = row_number(), 'tf' = n/total)#rank and term frequency column

Trump_tf %>%
  ggplot(aes(rank, tf)) +
  geom_line() +
  scale_x_log10() +
  scale_y_log10()
#zipf

tidy.trump<-filter(tidy.trump, !grepl('http', term)) #removing excess html adresses 

Trump_tfidf<-tidy.trump %>%
  bind_tf_idf(term, document, count)#tf-idf

Trump_tfidf<-Trump_tfidf %>%
  arrange(desc(tf_idf))


Trump_tfidf%>%
  arrange(desc(tf_idf))%>%
  head(20)%>%
  ggplot(aes(term, tf_idf)) +
  geom_col()+
  coord_flip()
  #visualize tf-idf

trump.sentiment<-tidy.trump %>%
  inner_join(get_sentiments("bing"), by = c(term = "word"))
#added bing sentiment to tweets

trump.sentiment %>%
  count(sentiment, term, wt = count) %>%
  ungroup() %>%
  filter(n >= 10) %>% #low frequency required to pick out more terms
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  mutate(term = reorder(term, n)) %>%
  ggplot(aes(term, n , fill = sentiment)) +
  ylab("Sentiment") +
  geom_bar(stat = "identity") +
  coord_flip()
#visulizations of scores

trump.trigram<-tweet.df %>%
  unnest_tokens(trigrams, text, token = "ngrams" , n=3)%>%
  count(trigrams, sort = TRUE) #creating trigrams

trump.trigram<- trump.trigram%>%
  separate(trigrams, c("word1", "word2", "word3"), sep = " ")%>%
  filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word, !word3 %in% stop_words$word)%>%
  filter(!word1 == "https", !word2 == "https", !word3 == "https")%>%
  filter(!word1 < 1000000, !word2 < 1000000, !word3 < 1000000)#the only way I figured out how to remove numbers


  



library(igraph)
library(ggraph)

set.seed(1234)

a<-grid::arrow(type = "closed", length = unit (.10, "inches"))#arrow creation

trump.trigram %>% #trigram mapping
  filter(n>15)%>%
  graph_from_data_frame() %>%
  ggraph(layout = 'fr')+
  geom_edge_link(aes(edge_alpha = n), arrow = a) +
  geom_node_point(color = "red") +
  geom_node_text(aes(label = name))+
  theme_void()


trump.unite<-trump.trigram%>%
  unite(trigram, word1, word2, word3, sep = " ")


trump.unite1<-trump.unite %>%
  filter(str_detect(trigram, "#sentiment#"))#will add highest and lowest sentiments to contextualize 



trump.unite1 %>%
  arrange(desc(n))%>%
  top_n(10) %>%
  ggplot(aes(trigram, n, fill = n)) +
  geom_col() +
  coord_flip()
#visulizations of trigrams

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
